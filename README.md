# ğŸ™ï¸ Speech Emotion Recognition (SER)

A comprehensive Speech Emotion Recognition system using Machine Learning and Deep Learning techniques. This project provides both a web interface and command-line tools for analyzing emotions in speech audio.

## ğŸš€ Quick Start

### Prerequisites
- Python 3.8+
- macOS (Apple Silicon recommended for best performance)

### Installation

1. **Clone the repository**
   ```bash
   git clone <repository-url>
   cd Speech-Emotion-Recognition-using-ML-and-DL
   ```

2. **Create virtual environment**
   ```bash
   python -m venv .venv
   source .venv/bin/activate  # On macOS/Linux
   ```

3. **Install dependencies**
   ```bash
   pip install --upgrade pip setuptools wheel
   pip install -r requirements.txt
   ```

4. **For Apple Silicon Macs (M1/M2)**
   ```bash
   pip install tensorflow-macos tensorflow-metal
   ```

### Running the Application

#### Web Interface (Recommended)
```bash
# Option 1: Use the root-level entry point (recommended)
streamlit run app.py

# Option 2: Run the package directly
streamlit run src/ser/app.py
```
This opens a beautiful web interface where you can:
- Choose from example audio files
- Upload your own WAV files
- View predictions with emojis and confidence scores
- See audio visualizations (waveform and mel spectrogram)

#### Command Line Interface
```bash
# Predict a single file
python -m src.ser.inference data/examples/03-01-01-01-01-02-05.wav

# Predict all example files
python -m src.ser.inference --examples

# Use helper script
./scripts/predict.sh data/examples/03-01-01-01-01-02-05.wav

# Run all examples with helper script
./scripts/predict.sh -e
```

## ğŸ“ Repository Structure

```
.
â”œâ”€â”€ src/
â”‚   â””â”€â”€ ser/                    # Main package
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ config.py           # Configuration and paths
â”‚       â”œâ”€â”€ features.py         # Feature extraction
â”‚       â”œâ”€â”€ model.py            # Model loading and prediction
â”‚       â”œâ”€â”€ inference.py        # CLI interface
â”‚       â”œâ”€â”€ datasets/
â”‚       â”‚   â””â”€â”€ tess.py         # TESS dataset processing
â”‚       â””â”€â”€ app.py              # Web interface
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ predict.sh              # Quick prediction script
â”‚   â”œâ”€â”€ rebuild_features.sh     # Feature extraction script
â”‚   â””â”€â”€ restore_from_quarantine.py # File restore tool
â”œâ”€â”€ models/
â”‚   â””â”€â”€ SER_model.h5            # Trained model
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                    # Raw datasets
â”‚   â”‚   â””â”€â”€ tess/               # TESS dataset
â”‚   â”œâ”€â”€ processed/              # Processed data
â”‚   â”‚   â””â”€â”€ dataset_features/   # Feature files
â”‚   â””â”€â”€ examples/               # Example audio files
â”œâ”€â”€ notebooks/                  # Jupyter notebooks
â”œâ”€â”€ docs/                       # Documentation
â”œâ”€â”€ assets/                     # Media files
â”œâ”€â”€ .github/                    # GitHub workflows
â”œâ”€â”€ .gitattributes              # Git LFS configuration
â”œâ”€â”€ .gitignore                  # Git ignore rules
â”œâ”€â”€ app.py                      # Main web app entry point
â”œâ”€â”€ requirements.txt            # Dependencies
â””â”€â”€ to_be_deleted/              # Quarantine for legacy files
```

## ğŸ¯ Features

### Core Functionality
- **Emotion Recognition**: 8 emotion classes (neutral, calm, happy, sad, angry, fear, disgust, surprised)
- **MFCC Feature Extraction**: Mel-frequency cepstral coefficients for audio analysis
- **Deep Learning Model**: Conv1D neural network architecture
- **Cross-platform**: Works on macOS, Linux, and Windows

### Web Interface
- ğŸ¨ **Beautiful UI**: Modern, responsive design with dark theme
- ğŸ“Š **Visualizations**: Waveform and mel spectrogram displays
- ğŸ“ˆ **Probability Charts**: Interactive bar charts showing emotion probabilities
- ğŸµ **Audio Player**: Built-in audio playback
- ğŸ“ **File Upload**: Drag-and-drop WAV file upload
- ğŸ“± **Mobile Friendly**: Responsive design for all devices

### Command Line Tools
- **Single File Prediction**: Quick analysis of individual audio files
- **Batch Processing**: Process multiple files at once
- **Example Mode**: Test with included example files
- **Verbose Output**: Detailed logging and debugging

## ğŸ”§ Usage Examples

### Web Interface
1. **Activate virtual environment first:**
   ```bash
   source .venv/bin/activate
   ```
2. **Run the web app:**
   ```bash
   streamlit run app.py
   ```
3. Choose "Choose example" to test with included files
4. Or choose "Upload file" to analyze your own audio
5. Click "Analyze Audio" to see results

**âš ï¸ Important:** Always activate the virtual environment before running the web app to avoid TensorFlow import errors.

### Command Line
```bash
# Basic prediction
python -m src.ser.inference audio.wav

# Verbose output
python -m src.ser.inference -v audio.wav

# Process all examples
python -m src.ser.inference --examples

# Use helper script
./scripts/predict.sh -e  # Examples
./scripts/predict.sh audio.wav  # Single file
```

### Feature Extraction
```bash
# Rebuild features from audio files
./scripts/rebuild_features.sh

# Or run directly
python -m src.ser.features
```

## ğŸ§  Model Architecture

The system uses a Conv1D neural network:
- **Input**: 40 MFCC features
- **Architecture**: 3 Conv1D layers with dropout and max pooling
- **Output**: 8 emotion classes with softmax activation
- **Training**: Adam optimizer with categorical crossentropy loss

## ğŸ“Š Supported Emotions

| Emotion | Emoji | Description |
|---------|-------|-------------|
| Neutral | ğŸ˜ | Calm, unemotional speech |
| Calm | ğŸ˜Œ | Relaxed, peaceful speech |
| Happy | ğŸ˜Š | Joyful, positive speech |
| Sad | ğŸ˜¢ | Melancholic, sorrowful speech |
| Angry | ğŸ˜  | Hostile, aggressive speech |
| Fear | ğŸ˜¨ | Anxious, scared speech |
| Disgust | ğŸ¤¢ | Repulsed, contemptuous speech |
| Surprised | ğŸ˜® | Astonished, shocked speech |

## ğŸ” Troubleshooting

### Safety Net
If something breaks after cleanup, you can restore files from quarantine:
```bash
# Show what would be restored (dry run)
python scripts/restore_from_quarantine.py --dry-run

# Restore all files from quarantine
python scripts/restore_from_quarantine.py
```

### Common Issues

**Model Loading Error**
```bash
# Ensure model file exists
ls models/SER_model.h5
```

**Audio File Issues**
- Ensure files are in WAV format
- Check file permissions
- Verify audio is not corrupted

**Import Errors**
```bash
# Reinstall dependencies
pip install -r requirements.txt --force-reinstall
```

**macOS TensorFlow Issues**
```bash
# For Apple Silicon
pip install tensorflow-macos tensorflow-metal

# For Intel Macs
pip install tensorflow
```

### Environment Setup
```bash
# Check Python version
python --version  # Should be 3.8+

# Verify virtual environment
which python  # Should point to .venv/bin/python

# Test imports
python -c "import tensorflow, librosa, streamlit; print('All good!')"
```

## ğŸ“ˆ Performance

- **Accuracy**: ~85% on test set
- **Inference Time**: ~100ms per audio file
- **Memory Usage**: ~200MB for model loading
- **Supported Audio**: 16kHz, mono WAV files

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests if applicable
5. Submit a pull request

## ğŸ“„ License

This project is licensed under the MIT License - see the LICENSE file for details.

## ğŸ™ Acknowledgments

- **RAVDESS Dataset**: Ryerson Audio-Visual Database of Emotional Speech and Song
- **TESS Dataset**: Toronto Emotional Speech Set
- **Librosa**: Audio and music signal processing library
- **Streamlit**: Web application framework
- **TensorFlow**: Deep learning framework

## ğŸ“ Support

For issues and questions:
1. Check the troubleshooting section
2. Review the project documentation
3. Open an issue on GitHub

---

**Made with â¤ï¸ for Speech Emotion Recognition**
